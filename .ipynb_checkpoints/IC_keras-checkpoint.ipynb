{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"physical_devices-------------\", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "###Depois descomentar aqui\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura  e visualização da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_excel('ic.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>Acidez</th>\n",
       "      <th>Aw</th>\n",
       "      <th>Umidade</th>\n",
       "      <th>ST</th>\n",
       "      <th>Brix</th>\n",
       "      <th>Cor - L*</th>\n",
       "      <th>Cor - a*</th>\n",
       "      <th>Cor - b*</th>\n",
       "      <th>sig</th>\n",
       "      <th>w1_915</th>\n",
       "      <th>w1_2450</th>\n",
       "      <th>w2_915</th>\n",
       "      <th>w2_2450</th>\n",
       "      <th>e1_915</th>\n",
       "      <th>e1_2450</th>\n",
       "      <th>e2_915</th>\n",
       "      <th>e2_2450</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>60</td>\n",
       "      <td>0.602444</td>\n",
       "      <td>0.948</td>\n",
       "      <td>92.991176</td>\n",
       "      <td>7.008824</td>\n",
       "      <td>29.63</td>\n",
       "      <td>39.690000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>3.748461</td>\n",
       "      <td>0.994881</td>\n",
       "      <td>0.986840</td>\n",
       "      <td>1.481341</td>\n",
       "      <td>1.296540</td>\n",
       "      <td>68.01840</td>\n",
       "      <td>67.22015</td>\n",
       "      <td>6.05872</td>\n",
       "      <td>6.66550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>60</td>\n",
       "      <td>0.640485</td>\n",
       "      <td>0.953</td>\n",
       "      <td>89.983175</td>\n",
       "      <td>10.016825</td>\n",
       "      <td>12.88</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>13.030000</td>\n",
       "      <td>8.785722</td>\n",
       "      <td>0.970822</td>\n",
       "      <td>0.944616</td>\n",
       "      <td>2.944587</td>\n",
       "      <td>1.562727</td>\n",
       "      <td>65.63748</td>\n",
       "      <td>63.74590</td>\n",
       "      <td>19.41012</td>\n",
       "      <td>11.75590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>10</td>\n",
       "      <td>0.632628</td>\n",
       "      <td>0.954</td>\n",
       "      <td>90.070932</td>\n",
       "      <td>9.929068</td>\n",
       "      <td>12.78</td>\n",
       "      <td>43.140000</td>\n",
       "      <td>-1.420000</td>\n",
       "      <td>13.830000</td>\n",
       "      <td>3.909667</td>\n",
       "      <td>0.933287</td>\n",
       "      <td>0.891836</td>\n",
       "      <td>1.779939</td>\n",
       "      <td>1.158260</td>\n",
       "      <td>77.69662</td>\n",
       "      <td>72.51310</td>\n",
       "      <td>14.71736</td>\n",
       "      <td>18.35840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0.056794</td>\n",
       "      <td>0.956</td>\n",
       "      <td>91.539304</td>\n",
       "      <td>32.769800</td>\n",
       "      <td>7.78</td>\n",
       "      <td>65.850000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>32.590000</td>\n",
       "      <td>0.484600</td>\n",
       "      <td>0.956924</td>\n",
       "      <td>0.928028</td>\n",
       "      <td>1.235806</td>\n",
       "      <td>1.054883</td>\n",
       "      <td>81.28427</td>\n",
       "      <td>76.68500</td>\n",
       "      <td>8.46249</td>\n",
       "      <td>17.36690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>0.162593</td>\n",
       "      <td>0.984</td>\n",
       "      <td>86.651121</td>\n",
       "      <td>33.093300</td>\n",
       "      <td>6.58</td>\n",
       "      <td>35.506667</td>\n",
       "      <td>-0.783333</td>\n",
       "      <td>-0.423333</td>\n",
       "      <td>1.152333</td>\n",
       "      <td>0.992871</td>\n",
       "      <td>1.011334</td>\n",
       "      <td>1.349007</td>\n",
       "      <td>1.100703</td>\n",
       "      <td>79.36730</td>\n",
       "      <td>76.99470</td>\n",
       "      <td>7.86732</td>\n",
       "      <td>12.93390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080595</td>\n",
       "      <td>0.993</td>\n",
       "      <td>88.777440</td>\n",
       "      <td>28.001800</td>\n",
       "      <td>11.76</td>\n",
       "      <td>32.700000</td>\n",
       "      <td>-0.783333</td>\n",
       "      <td>-0.423333</td>\n",
       "      <td>4.430667</td>\n",
       "      <td>0.950584</td>\n",
       "      <td>0.966461</td>\n",
       "      <td>2.149960</td>\n",
       "      <td>1.262102</td>\n",
       "      <td>75.86600</td>\n",
       "      <td>72.13340</td>\n",
       "      <td>17.73146</td>\n",
       "      <td>17.00750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>50</td>\n",
       "      <td>0.640485</td>\n",
       "      <td>0.953</td>\n",
       "      <td>89.983175</td>\n",
       "      <td>10.016825</td>\n",
       "      <td>12.88</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>13.030000</td>\n",
       "      <td>7.786388</td>\n",
       "      <td>0.963829</td>\n",
       "      <td>0.937601</td>\n",
       "      <td>2.731786</td>\n",
       "      <td>1.486015</td>\n",
       "      <td>67.99030</td>\n",
       "      <td>65.91400</td>\n",
       "      <td>17.99186</td>\n",
       "      <td>12.14730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>80</td>\n",
       "      <td>0.640485</td>\n",
       "      <td>0.953</td>\n",
       "      <td>89.983175</td>\n",
       "      <td>10.016825</td>\n",
       "      <td>12.88</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>13.030000</td>\n",
       "      <td>10.725722</td>\n",
       "      <td>0.974852</td>\n",
       "      <td>0.952007</td>\n",
       "      <td>3.403815</td>\n",
       "      <td>1.693362</td>\n",
       "      <td>62.16816</td>\n",
       "      <td>60.62020</td>\n",
       "      <td>22.62102</td>\n",
       "      <td>11.70850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>80</td>\n",
       "      <td>1.556349</td>\n",
       "      <td>0.955</td>\n",
       "      <td>89.885415</td>\n",
       "      <td>10.114585</td>\n",
       "      <td>26.38</td>\n",
       "      <td>33.130000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-1.590000</td>\n",
       "      <td>9.152816</td>\n",
       "      <td>0.964807</td>\n",
       "      <td>1.186616</td>\n",
       "      <td>1.850816</td>\n",
       "      <td>2.263748</td>\n",
       "      <td>60.83796</td>\n",
       "      <td>60.10450</td>\n",
       "      <td>9.99038</td>\n",
       "      <td>6.50680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>90</td>\n",
       "      <td>0.062703</td>\n",
       "      <td>0.957</td>\n",
       "      <td>91.567047</td>\n",
       "      <td>27.606100</td>\n",
       "      <td>7.88</td>\n",
       "      <td>65.930000</td>\n",
       "      <td>3.730000</td>\n",
       "      <td>32.590000</td>\n",
       "      <td>2.006392</td>\n",
       "      <td>0.983476</td>\n",
       "      <td>1.255498</td>\n",
       "      <td>1.491879</td>\n",
       "      <td>1.182592</td>\n",
       "      <td>59.54088</td>\n",
       "      <td>58.88850</td>\n",
       "      <td>6.00110</td>\n",
       "      <td>4.48030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>80</td>\n",
       "      <td>0.108326</td>\n",
       "      <td>0.975</td>\n",
       "      <td>92.304239</td>\n",
       "      <td>7.695761</td>\n",
       "      <td>30.31</td>\n",
       "      <td>52.560000</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>15.320000</td>\n",
       "      <td>3.987648</td>\n",
       "      <td>0.996821</td>\n",
       "      <td>0.989718</td>\n",
       "      <td>1.479371</td>\n",
       "      <td>1.377188</td>\n",
       "      <td>62.38296</td>\n",
       "      <td>61.84170</td>\n",
       "      <td>6.39970</td>\n",
       "      <td>5.19170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>20</td>\n",
       "      <td>0.108326</td>\n",
       "      <td>0.975</td>\n",
       "      <td>92.304239</td>\n",
       "      <td>7.695761</td>\n",
       "      <td>30.31</td>\n",
       "      <td>52.560000</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>15.320000</td>\n",
       "      <td>1.778788</td>\n",
       "      <td>0.962151</td>\n",
       "      <td>0.951554</td>\n",
       "      <td>1.232743</td>\n",
       "      <td>1.052875</td>\n",
       "      <td>77.12288</td>\n",
       "      <td>74.89130</td>\n",
       "      <td>6.73920</td>\n",
       "      <td>12.19070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>30</td>\n",
       "      <td>0.114207</td>\n",
       "      <td>0.971</td>\n",
       "      <td>92.341183</td>\n",
       "      <td>7.658817</td>\n",
       "      <td>30.23</td>\n",
       "      <td>52.560000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>15.310000</td>\n",
       "      <td>1.375330</td>\n",
       "      <td>0.970853</td>\n",
       "      <td>0.961769</td>\n",
       "      <td>1.293129</td>\n",
       "      <td>1.181774</td>\n",
       "      <td>74.53736</td>\n",
       "      <td>72.97530</td>\n",
       "      <td>6.15682</td>\n",
       "      <td>10.04180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>40</td>\n",
       "      <td>0.062703</td>\n",
       "      <td>0.957</td>\n",
       "      <td>91.567047</td>\n",
       "      <td>27.606100</td>\n",
       "      <td>7.88</td>\n",
       "      <td>65.930000</td>\n",
       "      <td>3.730000</td>\n",
       "      <td>32.590000</td>\n",
       "      <td>1.056911</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>1.049227</td>\n",
       "      <td>1.336363</td>\n",
       "      <td>1.135742</td>\n",
       "      <td>71.79636</td>\n",
       "      <td>70.56290</td>\n",
       "      <td>5.48920</td>\n",
       "      <td>8.23705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>90</td>\n",
       "      <td>0.538279</td>\n",
       "      <td>0.959</td>\n",
       "      <td>91.411839</td>\n",
       "      <td>8.588161</td>\n",
       "      <td>8.58</td>\n",
       "      <td>32.593333</td>\n",
       "      <td>-0.633333</td>\n",
       "      <td>5.803333</td>\n",
       "      <td>2.166000</td>\n",
       "      <td>0.990577</td>\n",
       "      <td>1.265180</td>\n",
       "      <td>1.430307</td>\n",
       "      <td>1.252586</td>\n",
       "      <td>60.59102</td>\n",
       "      <td>59.78150</td>\n",
       "      <td>6.12536</td>\n",
       "      <td>4.88620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>0.056794</td>\n",
       "      <td>0.956</td>\n",
       "      <td>91.539304</td>\n",
       "      <td>32.769800</td>\n",
       "      <td>7.78</td>\n",
       "      <td>65.850000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>32.590000</td>\n",
       "      <td>1.834000</td>\n",
       "      <td>0.987263</td>\n",
       "      <td>1.214496</td>\n",
       "      <td>1.410336</td>\n",
       "      <td>1.118249</td>\n",
       "      <td>62.65005</td>\n",
       "      <td>62.10010</td>\n",
       "      <td>5.61354</td>\n",
       "      <td>5.00650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>0.056794</td>\n",
       "      <td>0.956</td>\n",
       "      <td>91.539304</td>\n",
       "      <td>32.769800</td>\n",
       "      <td>7.78</td>\n",
       "      <td>65.850000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>32.590000</td>\n",
       "      <td>1.253667</td>\n",
       "      <td>0.980635</td>\n",
       "      <td>1.088957</td>\n",
       "      <td>1.374508</td>\n",
       "      <td>1.147763</td>\n",
       "      <td>69.83565</td>\n",
       "      <td>68.85995</td>\n",
       "      <td>5.33509</td>\n",
       "      <td>7.21160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>0.640485</td>\n",
       "      <td>0.953</td>\n",
       "      <td>89.983175</td>\n",
       "      <td>10.016825</td>\n",
       "      <td>12.88</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>13.030000</td>\n",
       "      <td>9.696000</td>\n",
       "      <td>0.972601</td>\n",
       "      <td>0.948325</td>\n",
       "      <td>3.449075</td>\n",
       "      <td>1.646802</td>\n",
       "      <td>63.34984</td>\n",
       "      <td>61.71600</td>\n",
       "      <td>21.55308</td>\n",
       "      <td>11.68350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>0.164489</td>\n",
       "      <td>0.986</td>\n",
       "      <td>86.687819</td>\n",
       "      <td>32.041800</td>\n",
       "      <td>6.78</td>\n",
       "      <td>35.553925</td>\n",
       "      <td>-0.752783</td>\n",
       "      <td>-0.377145</td>\n",
       "      <td>2.007244</td>\n",
       "      <td>1.003972</td>\n",
       "      <td>1.128183</td>\n",
       "      <td>1.638379</td>\n",
       "      <td>1.211513</td>\n",
       "      <td>70.95329</td>\n",
       "      <td>69.95025</td>\n",
       "      <td>7.40772</td>\n",
       "      <td>7.82880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.557757</td>\n",
       "      <td>0.959</td>\n",
       "      <td>91.347034</td>\n",
       "      <td>8.652966</td>\n",
       "      <td>8.68</td>\n",
       "      <td>32.599107</td>\n",
       "      <td>-0.601188</td>\n",
       "      <td>5.858409</td>\n",
       "      <td>0.607700</td>\n",
       "      <td>0.967562</td>\n",
       "      <td>0.950677</td>\n",
       "      <td>1.310825</td>\n",
       "      <td>1.112580</td>\n",
       "      <td>81.09296</td>\n",
       "      <td>76.85255</td>\n",
       "      <td>8.24799</td>\n",
       "      <td>16.42495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      T    Acidez     Aw    Umidade         ST   Brix   Cor - L*   Cor - a*  \\\n",
       "132  60  0.602444  0.948  92.991176   7.008824  29.63  39.690000  22.800000   \n",
       "93   60  0.640485  0.953  89.983175  10.016825  12.88  42.600000  -1.520000   \n",
       "82   10  0.632628  0.954  90.070932   9.929068  12.78  43.140000  -1.420000   \n",
       "60    5  0.056794  0.956  91.539304  32.769800   7.78  65.850000   3.900000   \n",
       "44   20  0.162593  0.984  86.651121  33.093300   6.58  35.506667  -0.783333   \n",
       "24   20  0.080595  0.993  88.777440  28.001800  11.76  32.700000  -0.783333   \n",
       "91   50  0.640485  0.953  89.983175  10.016825  12.88  42.600000  -1.520000   \n",
       "97   80  0.640485  0.953  89.983175  10.016825  12.88  42.600000  -1.520000   \n",
       "117  80  1.556349  0.955  89.885415  10.114585  26.38  33.130000  -0.250000   \n",
       "79   90  0.062703  0.957  91.567047  27.606100   7.88  65.930000   3.730000   \n",
       "157  80  0.108326  0.975  92.304239   7.695761  30.31  52.560000  18.770000   \n",
       "145  20  0.108326  0.975  92.304239   7.695761  30.31  52.560000  18.770000   \n",
       "146  30  0.114207  0.971  92.341183   7.658817  30.23  52.560000  18.750000   \n",
       "69   40  0.062703  0.957  91.567047  27.606100   7.88  65.930000   3.730000   \n",
       "18   90  0.538279  0.959  91.411839   8.588161   8.58  32.593333  -0.633333   \n",
       "76   80  0.056794  0.956  91.539304  32.769800   7.78  65.850000   3.900000   \n",
       "70   50  0.056794  0.956  91.539304  32.769800   7.78  65.850000   3.900000   \n",
       "95   70  0.640485  0.953  89.983175  10.016825  12.88  42.600000  -1.520000   \n",
       "51   50  0.164489  0.986  86.687819  32.041800   6.78  35.553925  -0.752783   \n",
       "3    10  0.557757  0.959  91.347034   8.652966   8.68  32.599107  -0.601188   \n",
       "\n",
       "      Cor - b*        sig    w1_915   w1_2450    w2_915   w2_2450    e1_915  \\\n",
       "132  16.900000   3.748461  0.994881  0.986840  1.481341  1.296540  68.01840   \n",
       "93   13.030000   8.785722  0.970822  0.944616  2.944587  1.562727  65.63748   \n",
       "82   13.830000   3.909667  0.933287  0.891836  1.779939  1.158260  77.69662   \n",
       "60   32.590000   0.484600  0.956924  0.928028  1.235806  1.054883  81.28427   \n",
       "44   -0.423333   1.152333  0.992871  1.011334  1.349007  1.100703  79.36730   \n",
       "24   -0.423333   4.430667  0.950584  0.966461  2.149960  1.262102  75.86600   \n",
       "91   13.030000   7.786388  0.963829  0.937601  2.731786  1.486015  67.99030   \n",
       "97   13.030000  10.725722  0.974852  0.952007  3.403815  1.693362  62.16816   \n",
       "117  -1.590000   9.152816  0.964807  1.186616  1.850816  2.263748  60.83796   \n",
       "79   32.590000   2.006392  0.983476  1.255498  1.491879  1.182592  59.54088   \n",
       "157  15.320000   3.987648  0.996821  0.989718  1.479371  1.377188  62.38296   \n",
       "145  15.320000   1.778788  0.962151  0.951554  1.232743  1.052875  77.12288   \n",
       "146  15.310000   1.375330  0.970853  0.961769  1.293129  1.181774  74.53736   \n",
       "69   32.590000   1.056911  0.976111  1.049227  1.336363  1.135742  71.79636   \n",
       "18    5.803333   2.166000  0.990577  1.265180  1.430307  1.252586  60.59102   \n",
       "76   32.590000   1.834000  0.987263  1.214496  1.410336  1.118249  62.65005   \n",
       "70   32.590000   1.253667  0.980635  1.088957  1.374508  1.147763  69.83565   \n",
       "95   13.030000   9.696000  0.972601  0.948325  3.449075  1.646802  63.34984   \n",
       "51   -0.377145   2.007244  1.003972  1.128183  1.638379  1.211513  70.95329   \n",
       "3     5.858409   0.607700  0.967562  0.950677  1.310825  1.112580  81.09296   \n",
       "\n",
       "      e1_2450    e2_915   e2_2450  \n",
       "132  67.22015   6.05872   6.66550  \n",
       "93   63.74590  19.41012  11.75590  \n",
       "82   72.51310  14.71736  18.35840  \n",
       "60   76.68500   8.46249  17.36690  \n",
       "44   76.99470   7.86732  12.93390  \n",
       "24   72.13340  17.73146  17.00750  \n",
       "91   65.91400  17.99186  12.14730  \n",
       "97   60.62020  22.62102  11.70850  \n",
       "117  60.10450   9.99038   6.50680  \n",
       "79   58.88850   6.00110   4.48030  \n",
       "157  61.84170   6.39970   5.19170  \n",
       "145  74.89130   6.73920  12.19070  \n",
       "146  72.97530   6.15682  10.04180  \n",
       "69   70.56290   5.48920   8.23705  \n",
       "18   59.78150   6.12536   4.88620  \n",
       "76   62.10010   5.61354   5.00650  \n",
       "70   68.85995   5.33509   7.21160  \n",
       "95   61.71600  21.55308  11.68350  \n",
       "51   69.95025   7.40772   7.82880  \n",
       "3    76.85255   8.24799  16.42495  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação entre variáveis dependentes e independentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base.iloc[:, 0:10].values\n",
    "\n",
    "#Vamos prever e1_945\n",
    "y = base['e1_915'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.reshape(y, (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_x = StandardScaler()\n",
    "X = scaler_x.fit_transform(X)\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação entre dados de treinamento e dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y,\n",
    "                                                                  test_size = 0.3,\n",
    "                                                                  random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição da arquitetura da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, input_dim = 10, activation = 'softmax'))\n",
    "# Prever todas saídas\n",
    "model.add(Dense(1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição da taxa de aprendizado (learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate =0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição da métrica Root Mean Squared Error (RMSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "\treturn backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar o backend do tensorflow (eu não sei exatamente porque precisei fazer isso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo do erro, otimizador e métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics= ['mae','mse',rmse])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumo de todos hiperparâmetros e arquitetura do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_treinamento, y_treinamento, \n",
    "          epochs=200,\n",
    "          batch_size = 30,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsões:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = model.predict(X_teste)\n",
    "\n",
    "test_predictions = model.predict(X_teste)\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(scaler_y.inverse_transform(y_teste), scaler_y.inverse_transform(test_predictions))\n",
    "plt.xlabel('True Values ')\n",
    "plt.ylabel('Predictions ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coeficiente de determinação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "acuracia_teste = r2_score(scaler_y.inverse_transform(y_teste),\n",
    "                          scaler_y.inverse_transform(test_predictions))\n",
    "\n",
    "previsao_todas = scaler_y.inverse_transform(model.predict(X_teste))\n",
    "y_teste_real = scaler_y.inverse_transform(y_teste)\n",
    "\n",
    "acuracia_teste"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
